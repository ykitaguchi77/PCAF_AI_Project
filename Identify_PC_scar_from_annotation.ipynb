{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9kOmfCjqIanQP544+PmfC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/PCAF_AI_Project/blob/main/Identify_PC_scar_from_annotation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Crop PC scar image using annotations**"
      ],
      "metadata": {
        "id": "8ypBS5ahQiNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "PCAF_AI_Project\n",
        "\n",
        "pt1_2_0M_Photo.png --> 位置合わせをした眼底画像（2000 x 2000 px）\n",
        "\n",
        "pt1_2_0M_Photo.txt\n",
        "label cx cy wx wy track_number\n",
        "0 0.724598 0.534400 0.010532 0.008982 158\n",
        "0 0.720320 0.544252 0.010541 0.007405 159\n",
        "0 0.722727 0.557084 0.012000 0.008595 160\n",
        "0 0.709630 0.568616 0.012195 0.008414 161\n",
        "\n",
        "このような感じでPCのアノーテーションが羅列されている。\n",
        "YOLOのtrack形式。labelはすべて0で統一。\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "rmZyyAG_VIlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: gdriveに接続\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTqKTx34Q1-z",
        "outputId": "cf4db7ce-e120-49d2-a1db-17ad8327c52d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 対応したラベルのあるpngファイルをリスト化"
      ],
      "metadata": {
        "id": "iaN0xc5mU8Ig"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RwZEBTpQOHc",
        "outputId": "b13bf039-1d49-47ad-d61d-f8347198d96a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['pt1_3_1.5M_Photo.png', 'pt1_4_2Y_Photo.png', 'pt1_5_1.5M_AF.png', 'pt1_6_2Y_AF.png']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "patient_dir = \"/content/drive/MyDrive/Deep_learning/PCAF_AI_Project/Patient_1\"\n",
        "\n",
        "png_files = [f for f in os.listdir(patient_dir) if f.endswith('.png')]\n",
        "\n",
        "# Extract numbers from filenames using regular expressions\n",
        "png_files.sort(key=lambda var: [int(x) if x.isdigit() else x\n",
        "                                   for x in re.findall(r'[^0-9]|[0-9]+', var)])\n",
        "\n",
        "# Filter PNG files based on corresponding TXT files\n",
        "filtered_png_files = [\n",
        "    png_file for png_file in png_files\n",
        "    if os.path.exists(os.path.join(patient_dir, os.path.splitext(png_file)[0] + '.txt'))\n",
        "]\n",
        "\n",
        "print(filtered_png_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ラベルの整理"
      ],
      "metadata": {
        "id": "NLB0fzn3Utld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# テキストファイル内の各行の先頭の数字（ラベル）を0に変更するスクリプト\n",
        "# 対象ファイル形式：スペース区切りのテキストファイル\n",
        "# 入力例：\n",
        "# label cx cy wx wy track_number\n",
        "# 1 0.619445 0.563755 0.008109 0.008600 150\n",
        "# 出力例：\n",
        "# 0 0.619445 0.563755 0.008109 0.008600 150\n",
        "\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "patient_dir = \"/content/drive/MyDrive/Deep_learning/PCAF_AI_Project/Patient_1\"\n",
        "\n",
        "# すべてのtxtファイルを取得\n",
        "txt_files = [f for f in os.listdir(patient_dir) if f.endswith('.txt')]\n",
        "\n",
        "# tqdmで進捗バーを表示\n",
        "for txt_file in tqdm(txt_files, desc=\"ファイル処理中\"):\n",
        "    file_path = os.path.join(patient_dir, txt_file)\n",
        "\n",
        "    # ファイルの内容を読み込む\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    # 各行の最初の数字を0に変更\n",
        "    modified_lines = []\n",
        "    for line in lines:\n",
        "        parts = line.split()\n",
        "        if parts:  # 空行でないことを確認\n",
        "            parts[0] = '0'  # 最初の数字を0に変更\n",
        "            modified_lines.append(' '.join(parts) + '\\n')\n",
        "\n",
        "    # 変更した内容を書き込む\n",
        "    with open(file_path, 'w') as file:\n",
        "        file.writelines(modified_lines)\n",
        "\n",
        "print(\"\\nすべてのファイルの処理が完了しました。\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-_wiATTS8cq",
        "outputId": "6d754d00-bccb-4214-8530-855366577233"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ファイル処理中: 100%|██████████| 5/5 [00:02<00:00,  2.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "すべてのファイルの処理が完了しました。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 概要：\n",
        "# 1. 全てのテキストファイルを走査し、トラッキング番号の出現状況を調べる\n",
        "# 2. 一部のファイルにしか出現しないトラッキング番号を検出\n",
        "# 3. 検出結果を表示し、ユーザーに削除の確認を取る\n",
        "# 4. 確認が取れたら、該当するトラッキング番号を含む行を全ファイルから削除\n",
        "#\n",
        "# 入力例：\n",
        "# label cx cy wx wy track_number\n",
        "# 1 0.619445 0.563755 0.008109 0.008600 150\n",
        "#\n",
        "# 処理内容：\n",
        "# - 全txtファイルの6列目(track_number)を確認\n",
        "# - 全ファイルに出現しないtrack_numberを検出\n",
        "# - 検出されたtrack_numberを含む行を各ファイルから削除\n",
        "# - 進捗状況をtqdmで表示\n",
        "# - ユーザー確認機能あり\n",
        "\n",
        "import os\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "\n",
        "def find_incomplete_tracking_numbers(patient_dir):\n",
        "    tracking_presence = defaultdict(set)\n",
        "    txt_files = [f for f in os.listdir(patient_dir) if f.endswith('.txt')]\n",
        "    total_files = len(txt_files)\n",
        "\n",
        "    print(f\"全ファイル数: {total_files}\")\n",
        "\n",
        "    # 各ファイルでのトラッキング番号の出現を記録\n",
        "    for txt_file in txt_files:\n",
        "        file_path = os.path.join(patient_dir, txt_file)\n",
        "        with open(file_path, 'r') as file:\n",
        "            for line in file:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) >= 6:\n",
        "                    try:\n",
        "                        track_number = int(parts[5])\n",
        "                        tracking_presence[track_number].add(txt_file)\n",
        "                    except (ValueError, IndexError):\n",
        "                        continue\n",
        "\n",
        "    # 全ファイルに出現していないトラッキング番号を抽出\n",
        "    incomplete_tracking = {\n",
        "        track_num: files\n",
        "        for track_num, files in tracking_presence.items()\n",
        "        if len(files) < total_files\n",
        "    }\n",
        "\n",
        "    return incomplete_tracking, txt_files\n",
        "\n",
        "def display_incomplete_tracks(incomplete_tracking, total_files):\n",
        "    print(f\"\\n全ファイルに出現していないトラッキング番号の数: {len(incomplete_tracking)}\")\n",
        "\n",
        "    # 詳細情報の表示\n",
        "    print(\"\\n===== 最初の10個の例 =====\")\n",
        "    for track_num, files in list(incomplete_tracking.items())[:10]:\n",
        "        print(f\"\\nトラッキング番号: {track_num}\")\n",
        "        print(f\"出現ファイル数: {len(files)} / {total_files}\")\n",
        "        print(f\"出現率: {(len(files)/total_files)*100:.1f}%\")\n",
        "\n",
        "def remove_incomplete_tracks(patient_dir, incomplete_tracking_nums):\n",
        "    txt_files = [f for f in os.listdir(patient_dir) if f.endswith('.txt')]\n",
        "\n",
        "    for txt_file in tqdm(txt_files, desc=\"ファイル処理中\"):\n",
        "        file_path = os.path.join(patient_dir, txt_file)\n",
        "\n",
        "        with open(file_path, 'r') as file:\n",
        "            lines = file.readlines()\n",
        "\n",
        "        new_lines = []\n",
        "        removed_count = 0\n",
        "        for line in lines:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) >= 6:\n",
        "                try:\n",
        "                    track_number = int(parts[5])\n",
        "                    if track_number not in incomplete_tracking_nums:\n",
        "                        new_lines.append(line)\n",
        "                    else:\n",
        "                        removed_count += 1\n",
        "                except (ValueError, IndexError):\n",
        "                    new_lines.append(line)\n",
        "            else:\n",
        "                new_lines.append(line)\n",
        "\n",
        "        with open(file_path, 'w') as file:\n",
        "            file.writelines(new_lines)\n",
        "\n",
        "    return removed_count\n",
        "\n",
        "def main():\n",
        "    patient_dir = \"/content/drive/MyDrive/Deep_learning/PCAF_AI_Project/Patient_1\"\n",
        "\n",
        "    print(\"不完全なトラッキング番号を検出中...\\n\")\n",
        "    incomplete_tracking, txt_files = find_incomplete_tracking_numbers(patient_dir)\n",
        "\n",
        "    # 検出結果の表示\n",
        "    display_incomplete_tracks(incomplete_tracking, len(txt_files))\n",
        "\n",
        "    # ユーザーに確認\n",
        "    while True:\n",
        "        response = input(\"\\nこれらのトラッキング番号を含む行を削除しますか？ (yes/no): \").lower()\n",
        "        if response in ['yes', 'no']:\n",
        "            break\n",
        "        print(\"'yes' または 'no' で入力してください。\")\n",
        "\n",
        "    if response == 'yes':\n",
        "        print(\"\\n削除を実行します...\")\n",
        "        incomplete_tracking_nums = set(incomplete_tracking.keys())\n",
        "        total_removed = remove_incomplete_tracks(patient_dir, incomplete_tracking_nums)\n",
        "        print(f\"\\n処理が完了しました。\")\n",
        "        print(f\"削除された行の総数: {total_removed}\")\n",
        "    else:\n",
        "        print(\"\\n処理を中止しました。\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaNVa6dcdUIu",
        "outputId": "eae7bafd-1eef-49d5-acaf-4870ab62a8fd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "不完全なトラッキング番号を検出中...\n",
            "\n",
            "全ファイル数: 5\n",
            "\n",
            "全ファイルに出現していないトラッキング番号の数: 0\n",
            "\n",
            "===== 最初の10個の例 =====\n",
            "\n",
            "これらのトラッキング番号を含む行を削除しますか？ (yes/no): no\n",
            "\n",
            "処理を中止しました。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Crop PC scar**"
      ],
      "metadata": {
        "id": "8mOY4EIUWpGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "kwrOchrMSGmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install japanize_matplotlib --q\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import seaborn as sns\n",
        "import glob\n",
        "import os\n",
        "\n",
        "def analyze_size_distribution(patient_dir, output_dir):\n",
        "    \"\"\"\n",
        "    ディレクトリ内の全txtファイルの凝固斑サイズ分布を分析\n",
        "    \"\"\"\n",
        "    # txtファイルを検索\n",
        "    txt_files = glob.glob(os.path.join(patient_dir, '*.txt'))\n",
        "    if not txt_files:\n",
        "        print(f\"警告: {patient_dir} 内にtxtファイルが見つかりませんでした。\")\n",
        "        return None\n",
        "\n",
        "    # 全ファイルのデータを読み込み\n",
        "    all_data = []\n",
        "    for txt_path in txt_files:\n",
        "        # データの読み込み\n",
        "        columns = ['label', 'cx', 'cy', 'wx', 'wy', 'track_number']\n",
        "        df = pd.read_csv(txt_path, sep=' ', names=columns)\n",
        "\n",
        "        # バウンディングボックスの面積を計算\n",
        "        df['area'] = df['wx'] * df['wy']\n",
        "        # ファイル名を追加\n",
        "        df['file'] = Path(txt_path).stem\n",
        "        all_data.append(df)\n",
        "\n",
        "    # 全データを結合\n",
        "    combined_df = pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "    # 出力ディレクトリの作成\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # 1. ヒストグラムの作成（ファイル毎に並べて表示）\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    unique_files = sorted(combined_df['file'].unique())\n",
        "    n_files = len(unique_files)\n",
        "\n",
        "    for i, file in enumerate(unique_files, 1):\n",
        "        plt.subplot(1, n_files, i)\n",
        "        file_data = combined_df[combined_df['file'] == file]\n",
        "        plt.hist(file_data['area'], bins=30, alpha=0.7)\n",
        "        plt.title(f'{file}')\n",
        "        plt.xlabel('凝固斑面積')\n",
        "        if i == 1:\n",
        "            plt.ylabel('頻度')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    histogram_path = os.path.join(output_dir, 'size_histograms.png')\n",
        "    plt.savefig(histogram_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    # 2. 箱ひげ図の作成\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.boxplot(x='file', y='area', data=combined_df)\n",
        "    plt.title('ファイル毎の凝固斑サイズ分布')\n",
        "    plt.xlabel('ファイル名')\n",
        "    plt.ylabel('凝固斑面積')\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    boxplot_path = os.path.join(output_dir, 'size_boxplot.png')\n",
        "    plt.savefig(boxplot_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    # 基本統計量の計算\n",
        "    stats = combined_df.groupby('file')['area'].describe()\n",
        "    print(\"\\n各ファイルの統計情報:\")\n",
        "    print(stats)\n",
        "\n",
        "    return stats\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    patient_dir = \"/content/drive/MyDrive/Deep_learning/PCAF_AI_Project/Patient_1\"\n",
        "    output_dir = os.path.join(patient_dir, 'size_distribution_analysis')\n",
        "    stats = analyze_size_distribution(patient_dir, output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W91IiqgKdNXc",
        "outputId": "e9669dd5-26bf-4cf5-9f46-b05b9812e9dd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting japanize_matplotlib\n",
            "  Downloading japanize-matplotlib-1.1.3.tar.gz (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from japanize_matplotlib) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->japanize_matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->japanize_matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->japanize_matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->japanize_matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib->japanize_matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->japanize_matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->japanize_matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->japanize_matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->japanize_matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->japanize_matplotlib) (1.17.0)\n",
            "Building wheels for collected packages: japanize_matplotlib\n",
            "  Building wheel for japanize_matplotlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for japanize_matplotlib: filename=japanize_matplotlib-1.1.3-py3-none-any.whl size=4120257 sha256=fdddf8291e55a9e4c9bfc12d256dd28a6aa9972a3e0297941aef74477ef7c85c\n",
            "  Stored in directory: /root/.cache/pip/wheels/da/a1/71/b8faeb93276fed10edffcca20746f1ef6f8d9e071eee8425fc\n",
            "Successfully built japanize_matplotlib\n",
            "Installing collected packages: japanize_matplotlib\n",
            "Successfully installed japanize_matplotlib-1.1.3\n",
            "\n",
            "各ファイルの統計情報:\n",
            "                   count      mean       std       min       25%       50%  \\\n",
            "file                                                                         \n",
            "pt1_2_0MPhoto      998.0  0.000151  0.000053  0.000030  0.000115  0.000146   \n",
            "pt1_3_1.5M_Photo  1004.0  0.000151  0.000061  0.000023  0.000114  0.000146   \n",
            "pt1_4_2Y_Photo    1005.0  0.000154  0.000063  0.000021  0.000113  0.000148   \n",
            "pt1_5_1.5M_AF      998.0  0.000153  0.000060  0.000023  0.000115  0.000146   \n",
            "pt1_6_2Y_AF       1004.0  0.000158  0.000066  0.000021  0.000117  0.000150   \n",
            "\n",
            "                       75%       max  \n",
            "file                                  \n",
            "pt1_2_0MPhoto     0.000176  0.000597  \n",
            "pt1_3_1.5M_Photo  0.000176  0.000824  \n",
            "pt1_4_2Y_Photo    0.000188  0.000597  \n",
            "pt1_5_1.5M_AF     0.000180  0.000625  \n",
            "pt1_6_2Y_AF       0.000189  0.000729  \n"
          ]
        }
      ]
    }
  ]
}